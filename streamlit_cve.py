import streamlit as st
import os, json, re
from typing import List
from sentence_transformers import SentenceTransformer, util
from groq import Groq
from pinecone import Pinecone
from dotenv import load_dotenv
import warnings
import transformers
import torch
from collections import defaultdict
from datetime import datetime

# Suppress warnings
warnings.filterwarnings("ignore")
transformers.logging.set_verbosity_error()

# Set environment variable to disable tokenizer parallelism
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# Load environment variables
load_dotenv()

# Initialize Groq client
client = Groq(api_key=os.getenv("GROQ_API_KEY"))

# Initialize Pinecone
pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
index_name = os.getenv("PINECONE_INDEX_NAME")
index_host = os.getenv("PINECONE_HOST")
index = pc.Index(name=index_name, host=index_host)

def prepare_db_metadata(index) -> dict:
    # Get total number of CVEs
    total_cves = index.describe_index_stats()['total_vector_count']

    # Initialize counters
    states = defaultdict(int)
    years = defaultdict(int)
    earliest_date = datetime.now()
    latest_date = datetime(1970, 1, 1)

    # Fetch all CVEs (you might need to do this in batches if you have a large number of CVEs)
    results = index.query(
        vector=[0] * 1536,  # Dummy vector
        top_k=10000,
        include_metadata=True
    )

    for match in results['matches']:
        metadata = match['metadata']
        
        # Count states
        state = metadata.get('state', 'UNKNOWN')
        states[state] += 1

        # Count years and track date range
        published_date = metadata.get('datePublished', '')
        if published_date:
            try:
                date = datetime.strptime(published_date, '%Y-%m-%d')
                years[date.year] += 1
                earliest_date = min(earliest_date, date)
                latest_date = max(latest_date, date)
            except ValueError:
                # Handle invalid date format
                pass

    # Prepare the metadata dictionary
    metadata = {
        "total_cves": total_cves,
        "date_range": f"{earliest_date.strftime('%B %d, %Y')} to {latest_date.strftime('%B %d, %Y')}",
        "cves_by_state": dict(states),
        "cves_by_year": dict(years)
    }

    return metadata

@st.cache_data(ttl=60)  # Cache for 1 hour
def get_db_metadata(_index):
    return prepare_db_metadata(index)

# Retrieve relevant CVEs
@st.cache_data
def retrieve_relevant_info(query: str, top_k: int = int(os.getenv("K_NEIGHBORS")), final_k: int = int(os.getenv("FINAL_K"))) -> List[dict]:
    extracted_fields = extract_cve_id(query)
    # extracted_cve_state = extract_cve_state(query)
    filter_dict = {}
    if extracted_fields:
        filter_dict["id"] = extracted_fields
    # if extracted_cve_state:
    #     filter_dict["state"] = extracted_cve_state
    
    model = SentenceTransformer(os.getenv("SENTENCE_TRANSFORMER_MODEL"))
    query_embedding = model.encode(query).tolist()
    
    
    # Pad the embedding to 1536 dimensions
    query_embedding += [0.0] * (1536 - len(query_embedding))

    print(extracted_fields)

        # If we have a filter, use it in the query
    if extracted_fields:
        print("Filtering results w/CVEID")
        results = index.query(
            vector=query_embedding,   
            filter={"id": extracted_fields},
            top_k=top_k,
            include_metadata=True,
            include_values=True
        )
    # elif extracted_cve_state!= "":
    #     print("Filtering results w/Others")
    #     results = index.query(
    #         vector=query_embedding,   
    #         filter=filter_dict,
    #         top_k=top_k,
    #         include_metadata=True,
    #         include_values=True
    #     )
    else:
        print("No filter")
        results = index.query(
            vector=query_embedding, 
            top_k=top_k, 
            include_metadata=True,
            include_values=True
        )
    # print(results)
    return [match['metadata'] for match in results['matches']]

     # Extract embeddings and metadata from results
    embeddings = [torch.tensor(match['values']) for match in results['matches']]
    metadata = [match['metadata'] for match in results['matches']]
    
    # Calculate cosine similarities
    similarities = util.pytorch_cos_sim(query_embedding, torch.stack(embeddings))[0]
    
    # Create a list of (similarity, metadata) tuples
    ranked_results = list(zip(similarities, metadata))
    
    # Sort by similarity (descending order) and take the top final_k
    ranked_results.sort(key=lambda x: x[0], reverse=True)
    top_results = ranked_results[:final_k]
    
    # Return only the metadata of the top results
    return [item[1] for item in top_results]

# Generate answer using Groq
def generate_answer(query: str, relevant_cves: List[dict]) -> str:
    context = "\n".join([
        f"CVE ID: {cve['id']}\n"
        f"Description: {cve['description']}\n"
        f"Published Date: {cve['datePublished']}\n"
        f"Updated Date: {cve['dateUpdated']}\n"
        f"References: {cve['references']}\n"
        # f"Title: {cve['title']}\n"
        f"Short Name: {cve['shortName']}\n"
        f"State: {cve['state']}\n"
        # f"Date Reserved: {cve['dateReserved']}\n"
        f"Date Rejected: {cve['dateRejected']}\n"
        for cve in relevant_cves
    ])
    # print(index.describe_index_stats())
    total_cves = index.describe_index_stats()['total_vector_count']
    db_metadata = get_db_metadata(index)
    print(db_metadata)
    # system_prompt = f"""You are a cybersecurity expert assistant specializing CVEs with access to a database of {total_cves} 
    # CVE (Common Vulnerabilities and Exposures) entries, which has details of CVE, Description, Published Date, Rejected Date, State, 
    # Updated Date, Reserved Date, Short name, References and Title. Your task is to provide accurate, detailed, and helpful answers 
    # to questions about these CVEs. Use the provided context to answer questions, but also use your general knowledge about 
    # cybersecurity when appropriate. If the information is not directly available in the context, say so, but try to provide 
    # relevant insights based on the available data and your expertise."""

    system_prompt = f"""You are a cybersecurity expert assistant specializing in CVEs. 
    Your primary task is to provide accurate & detailed answers to questions about CVEs based on the provided context. 
    If asked about a specific CVE that is not in the provided context, clearly state that you don't have information about that specific CVE in your database. 
    Use your general knowledge about cybersecurity when appropriate, but always prioritize the information given in the context. 

    You have access to a database of {total_cves} CVE entries, which has details of CVE ID, Description, Published Date, Rejected Date, State, 
    Updated Date, Reserved Date, Short name, References and Title."""
    
    user_prompt = f"""Context (Relevant CVEs):{context}, 
    Question: {query} 
    Please provide a detailed and informative answer, do not provide unnecessary details like based on context, metadata, etc. 
    If the question is about specific statistics or counts, make sure to reference the total number of CVEs ({total_cves}) and ({db_metadata}) in 
    the database when appropriate."""
    
    response = client.chat.completions.create(
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        # model="llama-3.1-70b-versatile",
        model=os.getenv("LLM_MODEL"),
        max_tokens=1000,
        temperature=float(os.getenv("LLM_TEMPERATURE")),
    )
    
    return response.choices[0].message.content

def extract_cve_id(query: str) -> str:
    """Extract CVE ID from the query if present, otherwise return an empty string."""
    cve_match = re.search(r'CVE-\d{4}-\d{4,7}', query, re.IGNORECASE)
    return cve_match.group(0).upper() if cve_match else ""

def extract_cve_state(query: str) -> str:
    """Extract CVE State from the query if present, otherwise return an empty string."""
    # Define possible state keywords
    state_keywords = ['published', 'rejected', 'reserved', 'disputed', 'deprecated']
    
    # Convert query to lowercase for case-insensitive matching
    query_lower = query.lower()
    
    # Check for each state keyword in the query
    for state in state_keywords:
        if state in query_lower:
            return state.capitalize()
    
    # If no state is found, check for the word "state" followed by any word
    state_match = re.search(r'state\s+(\w+)', query_lower)
    if state_match:
        return state_match.group(1).capitalize()
    
    # If no state is found, return an empty string
    return ""

def extract_query_fields(query: str) -> dict:

    system_prompt = """You are an AI assistant designed to extract relevant fields from user queries about CVEs (Common Vulnerabilities and Exposures). 
    The possible fields are: id, state, datePublished, dateUpdated, description, references, title, shortName, dateReserved, dateRejected.
    Extract only the fields explicitly mentioned or strongly implied in the user's query.
    Respond with only the relevant fields and their values. Do not include fields that are not mentioned or implied.
    If no fields are relevant, respond with an empty JSON object: {}"""

    user_prompt = f"Extract relevant fields from this query: {query}"

    response = client.chat.completions.create(
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        model=os.getenv("LLM_MODEL"),
        max_tokens=200,
        temperature=0.2,
    )
    
    content = response.choices[0].message.content
    # print(content)
    # Extract fields from the response
    extracted_fields = {}
    for line in content.split('\n'):
        if ':' in line:
            key, value = line.split(':', 1)
            key = key.strip().lower()
            value = value.strip()
            if value and value != '[if mentioned]' and value != '[date if mentioned]':
                extracted_fields[key] = value

    # Special handling for CVE ID
    cve_match = re.search(r'CVE-\d{4}-\d{4,7}', query, re.IGNORECASE)
    if cve_match:
        extracted_fields['id'] = cve_match.group(0).upper()

    return extracted_fields

# Streamlit app
st.title("CVE Question-Answering GPT")

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display chat messages from history on app rerun
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# React to user input
if prompt := st.chat_input("Ask me questions related CVEs?"):
    # Display user message in chat message container
    st.chat_message("user").markdown(prompt)
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})

    # Generate response
    with st.spinner('Searching for relevant CVEs and generating answer...'):
        relevant_cves = retrieve_relevant_info(prompt)
        response = generate_answer(prompt, relevant_cves)

    # Display assistant response in chat message container
    with st.chat_message("assistant"):
        st.markdown(response)
    # Add assistant response to chat history
    st.session_state.messages.append({"role": "assistant", "content": response})

# Add a sidebar with information about the system
st.sidebar.title("About")
st.sidebar.info(
    "This CVE Question-Answering GPT uses embeddings from Pinecone Vector database "
    "to retrieve relevant CVE information, using Llama-3.1 model "
    "to generate detailed answers to your questions about Common Vulnerabilities and Exposures."
)
st.sidebar.title("Pinecone DB Info:")
total_cves = index.describe_index_stats()['total_vector_count']
st.sidebar.metric("Total CVEs in DB", total_cves)

if st.sidebar.button("Clear Conversation History"):
    st.session_state.messages = []
    st.rerun()
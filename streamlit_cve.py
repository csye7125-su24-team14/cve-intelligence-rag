import streamlit as st
import os, json, re
from typing import List
from sentence_transformers import SentenceTransformer, util
from groq import Groq
from pinecone import Pinecone
from dotenv import load_dotenv
import warnings
import transformers
import torch

# Suppress warnings
warnings.filterwarnings("ignore")
transformers.logging.set_verbosity_error()

# Set environment variable to disable tokenizer parallelism
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# Load environment variables
load_dotenv()

# Initialize Groq client
client = Groq(api_key=os.getenv("GROQ_API_KEY"))

# Initialize Pinecone
pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
index_name = os.getenv("PINECONE_INDEX_NAME")
index_host = os.getenv("PINECONE_HOST")
index = pc.Index(name=index_name, host=index_host)

# Retrieve relevant CVEs
@st.cache_data
def retrieve_relevant_info(query: str, top_k: int = int(os.getenv("K_NEIGHBORS")), final_k: int = int(os.getenv("FINAL_K"))) -> List[dict]:
    extracted_fields = extract_cve_id(query)
    extracted_cve_state = extract_cve_state(query)
    filter_dict = {}
    if extracted_fields:
        filter_dict["id"] = extracted_fields
    if extracted_cve_state:
        filter_dict["state"] = extracted_cve_state
    
    model = SentenceTransformer(os.getenv("SENTENCE_TRANSFORMER_MODEL"))
    query_embedding = model.encode(query).tolist()
    
    # Pad the embedding to 1536 dimensions
    query_embedding += [0.0] * (1536 - len(query_embedding))

    print(extracted_fields)

        # If we have a filter, use it in the query
    if extracted_fields:
        print("Filtering results w/CVEID")
        results = index.query(
            vector=query_embedding,   
            filter={"id": extracted_fields},
            top_k=top_k,
            include_metadata=True,
            include_values=True
        )
    elif extracted_cve_state!= "":
        print("Filtering results w/Others")
        results = index.query(
            vector=query_embedding,   
            filter=filter_dict,
            top_k=top_k,
            include_metadata=True,
            include_values=True
        )
    else:
        print("No filter")
        results = index.query(
            vector=query_embedding, 
            top_k=top_k, 
            include_metadata=True,
            include_values=True
        )
    # print(results)
    return [match['metadata'] for match in results['matches']]

     # Extract embeddings and metadata from results
    embeddings = [torch.tensor(match['values']) for match in results['matches']]
    metadata = [match['metadata'] for match in results['matches']]
    
    # Calculate cosine similarities
    similarities = util.pytorch_cos_sim(query_embedding, torch.stack(embeddings))[0]
    
    # Create a list of (similarity, metadata) tuples
    ranked_results = list(zip(similarities, metadata))
    
    # Sort by similarity (descending order) and take the top final_k
    ranked_results.sort(key=lambda x: x[0], reverse=True)
    top_results = ranked_results[:final_k]
    
    # Return only the metadata of the top results
    return [item[1] for item in top_results]

# Generate answer using Groq
def generate_answer(query: str, relevant_cves: List[dict]) -> str:
    context = "\n".join([
        f"CVE ID: {cve['id']}\n"
        f"Description: {cve['description']}\n"
        f"Published Date: {cve['datePublished']}\n"
        f"Updated Date: {cve['dateUpdated']}\n"
        f"References: {cve['references']}\n"
        f"Title: {cve['title']}\n"
        f"Short Name: {cve['shortName']}\n"
        f"State: {cve['state']}\n"
        f"Date Reserved: {cve['dateReserved']}\n"
        f"Date Rejected: {cve['dateRejected']}\n"
        for cve in relevant_cves
    ])
    # print(index.describe_index_stats())
    total_cves = index.describe_index_stats()['total_vector_count']
    
    system_prompt = f"""You are a cybersecurity expert assistant specializing CVEs with access to a database of {total_cves} 
    CVE (Common Vulnerabilities and Exposures) entries, which has deatils of CVE, Description, Published Date, Rejected Date, State, 
    Updated Date, Reserved Date, Short name, References and Title. Your task is to provide accurate, detailed, and helpful answers 
    to questions about these CVEs. Use the provided context to answer questions, but also use your general knowledge about 
    cybersecurity when appropriate. If the information is not directly available in the context, say so, but try to provide 
    relevant insights based on the available data and your expertise."""
    
    user_prompt = f"""Context:{context}, Question: {query} Please provide a detailed and informative answer. 
    If the question is about specific statistics or counts, make sure to reference the total number of CVEs ({total_cves}) in 
    the database when appropriate."""
    
    response = client.chat.completions.create(
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        # model="llama-3.1-70b-versatile",
        model=os.getenv("LLM_MODEL"),
        max_tokens=1000,
        temperature=float(os.getenv("LLM_TEMPERATURE")),
    )
    
    return response.choices[0].message.content

# def extract_query_fields(query: str) -> dict:
#     system_prompt = """You are an AI assistant designed to extract relevant fields from user queries about CVEs (Common Vulnerabilities and Exposures). 
#     The possible fields are: CVE Id, state,Published Date,Updated Date, description, references, title, short Name, Reserved date, Rejected date.
#     Extract only the fields explicitly mentioned or implied in the user's query, query might not be straight forward."""

#     user_prompt = f"Extract relevant fields from this query: {query}"
#     print(user_prompt)
#     response = client.chat.completions.create(
#         messages=[
#             {"role": "system", "content": system_prompt},
#             {"role": "user", "content": user_prompt}
#         ],
#         model=os.getenv("LLM_MODEL"),
#         max_tokens=200,
#         temperature=0.2,
#     )
#     print(response)
#     try:
#         extracted_fields = json.loads(response.choices[0].message.content)
#         return extracted_fields
#     except json.JSONDecodeError:
#         st.warning("Failed to parse LLM response. Using default query.")
#         return {}
def extract_cve_id(query: str) -> str:
    """Extract CVE ID from the query if present, otherwise return an empty string."""
    cve_match = re.search(r'CVE-\d{4}-\d{4,7}', query, re.IGNORECASE)
    return cve_match.group(0).upper() if cve_match else ""

def extract_cve_state(query: str) -> str:
    """Extract CVE State from the query if present, otherwise return an empty string."""
    # Define possible state keywords
    state_keywords = ['published', 'rejected', 'reserved', 'disputed', 'deprecated']
    
    # Convert query to lowercase for case-insensitive matching
    query_lower = query.lower()
    
    # Check for each state keyword in the query
    for state in state_keywords:
        if state in query_lower:
            return state.capitalize()
    
    # If no state is found, check for the word "state" followed by any word
    state_match = re.search(r'state\s+(\w+)', query_lower)
    if state_match:
        return state_match.group(1).capitalize()
    
    # If no state is found, return an empty string
    return ""

def extract_query_fields(query: str) -> dict:
    # system_prompt = """You are an AI assistant designed to extract relevant fields from user queries about CVEs (Common Vulnerabilities and Exposures). 
    # The possible fields are: id, state, datePublished, dateUpdated, description, references, title, shortName, dateReserved, dateRejected.
    # Extract only the fields explicitly mentioned or strongly implied in the user's query.
    # Respond in the following format:
    # id: [CVE ID if mentioned]
    # state: [state if mentioned or implied]
    # datePublished: [date if mentioned]
    # dateUpdated: [date if mentioned]
    # description: [if details are requested]
    # references: [if mentioned]
    # title: [if mentioned]
    # shortName: [if mentioned]
    # dateReserved: [date if mentioned]
    # dateRejected: [date if mentioned]
    # Only include fields that are relevant to the query.
    # Do not include fields that are not mentioned or implied.
    # If no fields are relevant, respond with an empty JSON object"""

    system_prompt = """You are an AI assistant designed to extract relevant fields from user queries about CVEs (Common Vulnerabilities and Exposures). 
    The possible fields are: id, state, datePublished, dateUpdated, description, references, title, shortName, dateReserved, dateRejected.
    Extract only the fields explicitly mentioned or strongly implied in the user's query.
    Respond with only the relevant fields and their values. Do not include fields that are not mentioned or implied.
    If no fields are relevant, respond with an empty JSON object: {}"""

    user_prompt = f"Extract relevant fields from this query: {query}"

    response = client.chat.completions.create(
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        model=os.getenv("LLM_MODEL"),
        max_tokens=200,
        temperature=0.2,
    )
    
    content = response.choices[0].message.content
    # print(content)
    # Extract fields from the response
    extracted_fields = {}
    for line in content.split('\n'):
        if ':' in line:
            key, value = line.split(':', 1)
            key = key.strip().lower()
            value = value.strip()
            if value and value != '[if mentioned]' and value != '[date if mentioned]':
                extracted_fields[key] = value

    # Special handling for CVE ID
    cve_match = re.search(r'CVE-\d{4}-\d{4,7}', query, re.IGNORECASE)
    if cve_match:
        extracted_fields['id'] = cve_match.group(0).upper()

    return extracted_fields

# Streamlit app
st.title("CVE Question-Answering GPT")

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display chat messages from history on app rerun
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# React to user input
if prompt := st.chat_input("Ask me questions related CVEs?"):
    # Display user message in chat message container
    st.chat_message("user").markdown(prompt)
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})

    # Generate response
    with st.spinner('Searching for relevant CVEs and generating answer...'):
        relevant_cves = retrieve_relevant_info(prompt)
        response = generate_answer(prompt, relevant_cves)

    # Display assistant response in chat message container
    with st.chat_message("assistant"):
        st.markdown(response)
    # Add assistant response to chat history
    st.session_state.messages.append({"role": "assistant", "content": response})

# Add a sidebar with information about the system
st.sidebar.title("About")
st.sidebar.info(
    "This CVE Question-Answering GPT uses embeddings from Pinecone Vector database "
    "to retrieve relevant CVE information, using Llama-3.1 model "
    "to generate detailed answers to your questions about Common Vulnerabilities and Exposures."
)
st.sidebar.title("Pinecone DB Info:")
total_cves = index.describe_index_stats()['total_vector_count']
st.sidebar.metric("Total CVEs in DB", total_cves)

if st.sidebar.button("Clear Conversation History"):
    st.session_state.messages = []
    st.rerun()